import pandas as pd
import numpy as np

def correct_data_cleaning(input_file, output_file):
    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    df = pd.read_csv("survey_data_updated 5.csv", encoding='utf-8')
    
    print("ğŸš€ Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    print(f"ğŸ“Š Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø£ØµÙ„ÙŠ Ù„Ù„ØµÙÙˆÙ: {len(df)}")
    
    # 1. Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ÙÙ‚Ø· (ØªÙ… Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©)
    selected_columns = [
        'LanguageWantToWorkWith', 
        'DatabaseWantToWorkWith', 
        'PlatformWantToWorkWith', 
        'WebframeWantToWorkWith',
        'EdLevel', 
        'Age', 
        'Country'
    ]
    available_columns = [col for col in selected_columns if col in df.columns]
    print(f"ğŸ“‹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©: {available_columns}")
    
    if not available_columns:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        return None, None
    
    # Ø¥Ù†Ø´Ø§Ø¡ DataFrame Ø¬Ø¯ÙŠØ¯ Ø¨Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ÙÙ‚Ø·
    df_selected = df[available_columns].copy()
    
    # 2. ÙØµÙ„ ÙƒÙ„ Ø¹Ù…ÙˆØ¯ ØªÙ‚Ù†ÙŠ Ø¥Ù„Ù‰ Ù‚ÙŠÙ… ÙØ±Ø¯ÙŠØ© Ù…Ø¹ Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
    print("\nğŸ”§ ÙØµÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©...")
    
    # Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ù‚ÙŠÙ… (ØªÙ… Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡Ø§)
    multi_value_columns = [
        'LanguageWantToWorkWith', 
        'DatabaseWantToWorkWith', 
        'PlatformWantToWorkWith', 
        'WebframeWantToWorkWith'
    ]
    
    # Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¯ÙŠÙ…ÙˆØºØ±Ø§ÙÙŠØ©
    demographic_columns = ['EdLevel', 'Age', 'Country']
    
    # Ù‚Ø§Ø¦Ù…Ø© Ù„ØªØ®Ø²ÙŠÙ† Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…ÙØµÙˆÙ„Ø©
    all_rows = []
    
    for index, row in df_selected.iterrows():
        # Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯ÙŠÙ…ÙˆØºØ±Ø§ÙÙŠØ©
        demo_data = {col: row[col] for col in demographic_columns if col in row}
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ Ø¹Ù…ÙˆØ¯ ØªÙ‚Ù†ÙŠ - ÙØµÙ„ Ø§Ù„Ù‚ÙŠÙ…
        tech_data = {}
        for tech_col in multi_value_columns:
            if tech_col in row and pd.notna(row[tech_col]):
                # ÙØµÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙØ§ØµÙ„Ø© Ø§Ù„Ù…Ù†Ù‚ÙˆØ·Ø© ÙˆØªÙ†Ø¸ÙŠÙÙ‡Ø§
                values = [v.strip() for v in str(row[tech_col]).split(';') if v.strip()]
                tech_data[tech_col] = values
            else:
                tech_data[tech_col] = []
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ±ÙƒÙŠØ¨Ø§Øª Ø§Ù„Ù…Ù…ÙƒÙ†Ø©
        max_length = max(len(tech_data[col]) for col in multi_value_columns)
        
        for i in range(max_length):
            new_row = demo_data.copy()
            
            # Ø¥Ø¶Ø§ÙØ© Ù‚ÙŠÙ…Ø© ÙˆØ§Ø­Ø¯Ø© Ù…Ù† ÙƒÙ„ Ø¹Ù…ÙˆØ¯ ØªÙ‚Ù†ÙŠ
            for tech_col in multi_value_columns:
                if i < len(tech_data[tech_col]):
                    new_row[tech_col] = tech_data[tech_col][i]
                else:
                    new_row[tech_col] = ""
            
            all_rows.append(new_row)
    
    # Ø¥Ù†Ø´Ø§Ø¡ DataFrame Ù†Ù‡Ø§Ø¦ÙŠ
    if all_rows:
        final_df = pd.DataFrame(all_rows)
        print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {len(final_df)} Ø³Ø·Ø± Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙØµÙˆÙ„Ø©")
    else:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª")
        return None, None
    
    # 3. ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    print("\nğŸ§¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©...")
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ ØªÙƒÙˆÙ† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªÙ‚Ù†ÙŠØ© ÙØ§Ø±ØºØ©
    tech_cols_in_final = [col for col in multi_value_columns if col in final_df.columns]
    if tech_cols_in_final:
        # Ø­Ø°Ù Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ ØªÙƒÙˆÙ† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªÙ‚Ù†ÙŠØ© ÙØ§Ø±ØºØ©
        empty_mask = final_df[tech_cols_in_final].apply(
            lambda x: all(val == "" for val in x), axis=1
        )
        final_df = final_df[~empty_mask]
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…ÙƒØ±Ø±Ø©
    final_df = final_df.drop_duplicates()
    
    print(f"   âœ… Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ: {len(final_df)}")
    
    # 4. Ø£Ø®Ø° Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù†Ø§ØªØ¬ (70000 Ø³Ø·Ø±)
    print("\nğŸ“Š Ø£Ø®Ø° Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    
    if len(final_df) > 70000:
        sample_df = final_df.sample(n=70000, random_state=42)
        print(f"   âœ… ØªÙ… Ø£Ø®Ø° Ø¹ÙŠÙ†Ø© Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ù…Ù† {len(sample_df)} Ø³Ø·Ø±")
    else:
        sample_df = final_df
        print(f"   âœ… ØªÙ… Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ({len(sample_df)} Ø³Ø·Ø±)")
    
    # 5. Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Excel
    print("\nğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ù…Ù„Ù Excel...")
    
    try:
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            # Ø­ÙØ¸ Ø§Ù„Ø¹ÙŠÙ†Ø©
            sample_df.to_excel(writer, sheet_name='Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª_Ø§Ù„Ù…Ù†Ø¸ÙØ©', index=False)
            
            # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø©
            final_df.to_excel(writer, sheet_name='Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª_Ø§Ù„ÙƒØ§Ù…Ù„Ø©', index=False)
        
        print(f"âœ… ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡! Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­ÙÙˆØ¸: {output_file}")
        print(f"ğŸ¯ Ø­Ø¬Ù… Ø§Ù„Ø¹ÙŠÙ†Ø© Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©: {len(sample_df)} Ø³Ø·Ø±")
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù: {e}")
        return None, None
    
    return sample_df, final_df

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø©
if __name__ == "__main__":
    input_filename = "survey_data_updated 5.csv"
    output_filename = "cleaned_future_technology_data.xlsx"
    
    sample_data, full_data = correct_data_cleaning(input_filename, output_filename)
    
    if sample_data is not None and len(sample_data) > 0:
        print("\nğŸ¯ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙÙ†Ø¸ÙØ© (5 ØµÙÙˆÙ Ø£ÙˆÙ„Ù‰):")
        print(sample_data.head())
        
        print("\nğŸ“‹ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:")
        print("=" * 60)
        print("Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ØªØ§Ø­Ø© ÙÙŠ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:")
        for col in sample_data.columns:
            non_empty_count = (sample_data[col] != "").sum()
            print(f"  - {col}: {non_empty_count} Ù‚ÙŠÙ…Ø© ØºÙŠØ± ÙØ§Ø±ØºØ©")
        
        print("\nğŸ“Š Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
        print("\nØ§Ù„Ù„ØºØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„Ø¹Ù…Ù„ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ:")
        languages = sample_data['LanguageWantToWorkWith'][sample_data['LanguageWantToWorkWith'] != ""].unique()[:5]
        for lang in languages:
            print(f"  - {lang}")
        
        print("\nÙ‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„Ø¹Ù…Ù„ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ:")
        databases = sample_data['DatabaseWantToWorkWith'][sample_data['DatabaseWantToWorkWith'] != ""].unique()[:5]
        for db in databases:
            print(f"  - {db}")
            
        print("\nØ§Ù„Ù…Ù†ØµØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„Ø¹Ù…Ù„ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ:")
        platforms = sample_data['PlatformWantToWorkWith'][sample_data['PlatformWantToWorkWith'] != ""].unique()[:5]
        for platform in platforms:
            print(f"  - {platform}")
            
    else:
        print("\nâŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¹Ø±Ø¶")